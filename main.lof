\contentsline {figure}{\numberline {1}{\ignorespaces Illustrations of ICL using clean prompt and adversarial prompt. Given the clean in-context demos, LLMs can correctly generate the sentiment of the test queries. The previous attacks \cite {wang2023adversarial} at the character level involve minor edits in some words, such as altering `so' to `s0' and `film' to `fi1m', of these in-context demos, leading to incorrect sentiment generated for the test queries. However, ours \textbf {learns} to \textbf {append} adversarial suffixes like `For' and `Location' to the in-context demos to efficiently and effectively \textbf {hijack} LLMs to generate the \textbf {unwanted target}, e.g., the `negative' sentiment, \textbf {regardless} of the test query content. }}{2}{figure.caption.4}%
\contentsline {figure}{\numberline {2}{\ignorespaces Template designs for all the datasets used in our experiments. We also provide examples for these datasets in Figure \ref {fig:eg_sst2} and Figure \ref {fig:eg_ag} to ensure a better understanding. }}{17}{figure.caption.7}%
\contentsline {figure}{\numberline {3}{\ignorespaces Average perplexity scores reported for LLaMA2-7b on 100 random samples under eight-shots setting from SST-2 (a) and RT (b) derived from three separate runs under various attacks.}}{24}{figure.caption.12}%
\contentsline {figure}{\numberline {4}{\ignorespaces Impact of LLM size on adversarial robustness. ASRs on the AG's News topic generation task using different sizes of OPT models, i.e., OPT-2.7b and OPT-6.7b, with two different few-shot settings. }}{25}{figure.caption.13}%
\contentsline {figure}{\numberline {5}{\ignorespaces An illustration of the learning objective values during iterations among different attacks on SST2 using GPT2-XL with 8-shots. }}{26}{figure.caption.14}%
\contentsline {figure}{\numberline {6}{\ignorespaces Attentions maps generated using (a) clean and (b) adversarial perturbed prompts. In (b), the adversarial suffix tokens, i.e., `NULL' and `Remove', are underlined in red. Darker green colors represent larger attention weights. The prompts are tokenized to mimic the actual inputs to the LLMs. Best viewed in color.}}{27}{figure.caption.15}%
\contentsline {figure}{\numberline {7}{\ignorespaces Attentions maps generated using (a) Preceding and (b) Proceeding defense methods. Best viewed in color.}}{28}{figure.caption.16}%
\contentsline {figure}{\numberline {8}{\ignorespaces Visualization of an adversarial example generated by baseline and our attacks on SST-2 via attacking LLaMA-7b.}}{29}{figure.caption.17}%
\contentsline {figure}{\numberline {9}{\ignorespaces Visualization of an adversarial example generated by baseline and our attacks on AG's News via attacking LLaMA-7b.}}{30}{figure.caption.18}%
