@article{chao2023jailbreaking,
  title={Jailbreaking black box large language models in twenty queries},
  author={Chao, Patrick and Robey, Alexander and Dobriban, Edgar and Hassani, Hamed and Pappas, George J and Wong, Eric},
  journal={arXiv preprint arXiv:2310.08419},
  year={2023}
}
@article{pawelczyk2023context,
  title={In-context unlearning: Language models as few shot unlearners},
  author={Pawelczyk, Martin and Neel, Seth and Lakkaraju, Himabindu},
  journal={arXiv preprint arXiv:2310.07579},
  year={2023}
}
@article{schwarzschild2024rethinking,
  title={Rethinking LLM Memorization through the Lens of Adversarial Compression},
  author={Schwarzschild, Avi and Feng, Zhili and Maini, Pratyush and Lipton, Zachary C and Kolter, J Zico},
  journal={arXiv preprint arXiv:2404.15146},
  year={2024}
}
@article{nguyen2023context,
  title={In-context Example Selection with Influences},
  author={Nguyen, Tai and Wong, Eric},
  journal={arXiv preprint arXiv:2302.11042},
  year={2023}
}
@article{wei2023jailbreak,
  title={Jailbreak and guard aligned language models with only few in-context demonstrations},
  author={Wei, Zeming and Wang, Yifei and Wang, Yisen},
  journal={arXiv preprint arXiv:2310.06387},
  year={2023}
}

@article{kandpal2023backdoor,
  title={Backdoor attacks for in-context learning with language models},
  author={Kandpal, Nikhil and Jagielski, Matthew and Tram{\`e}r, Florian and Carlini, Nicholas},
  journal={arXiv preprint arXiv:2307.14692},
  year={2023}
}
@article{liu2020adversarial,
  title={Adversarial training for large neural language models},
  author={Liu, Xiaodong and Cheng, Hao and He, Pengcheng and Chen, Weizhu and Wang, Yu and Poon, Hoifung and Gao, Jianfeng},
  journal={arXiv preprint arXiv:2004.08994},
  year={2020}
}
@article{goyal2023survey,
  title={A survey of adversarial defenses and robustness in nlp},
  author={Goyal, Shreya and Doddapaneni, Sumanth and Khapra, Mitesh M and Ravindran, Balaraman},
  journal={ACM Computing Surveys},
  volume={55},
  number={14s},
  pages={1--39},
  year={2023},
  publisher={ACM New York, NY}
}
@article{mo2023test,
  title={Test-time backdoor mitigation for black-box large language models with defensive demonstrations},
  author={Mo, Wenjie and Xu, Jiashu and Liu, Qin and Wang, Jiongxiao and Yan, Jun and Xiao, Chaowei and Chen, Muhao},
  journal={arXiv preprint arXiv:2311.09763},
  year={2023}
}
@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}
@article{liu2023pre,
  title={Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing},
  author={Liu, Pengfei and Yuan, Weizhe and Fu, Jinlan and Jiang, Zhengbao and Hayashi, Hiroaki and Neubig, Graham},
  journal={ACM Computing Surveys},
  volume={55},
  number={9},
  pages={1--35},
  year={2023},
  publisher={ACM New York, NY}
}
@inproceedings{gao2018black,
  title={Black-box generation of adversarial text sequences to evade deep learning classifiers},
  author={Gao, Ji and Lanchantin, Jack and Soffa, Mary Lou and Qi, Yanjun},
  booktitle={2018 IEEE Security and Privacy Workshops (SPW)},
  pages={50--56},
  year={2018},
  organization={IEEE}
}
@article{wang2023adversarial,
  title={Adversarial Demonstration Attacks on Large Language Models},
  author={Wang, Jiongxiao and Liu, Zichen and Park, Keun Hee and Chen, Muhao and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2305.14950},
  year={2023}
}
@inproceedings{andriushchenko2020square,
  title={Square attack: a query-efficient black-box adversarial attack via random search},
  author={Andriushchenko, Maksym and Croce, Francesco and Flammarion, Nicolas and Hein, Matthias},
  booktitle={European conference on computer vision},
  pages={484--501},
  year={2020},
  organization={Springer}
}
@misc{zhang2022opt,
      title={OPT: Open Pre-trained Transformer Language Models}, 
      author={Susan Zhang and Stephen Roller and Naman Goyal and Mikel Artetxe and Moya Chen and Shuohui Chen and Christopher Dewan and Mona Diab and Xian Li and Xi Victoria Lin and Todor Mihaylov and Myle Ott and Sam Shleifer and Kurt Shuster and Daniel Simig and Punit Singh Koura and Anjali Sridhar and Tianlu Wang and Luke Zettlemoyer},
      year={2022},
      eprint={2205.01068},
      archivePrefix={arXiv},
      primaryClass={cs.CL}
}
@article{touvron2023llama,
  title={Llama: Open and efficient foundation language models},
  author={Touvron, Hugo and Lavril, Thibaut and Izacard, Gautier and Martinet, Xavier and Lachaux, Marie-Anne and Lacroix, Timoth{\'e}e and Rozi{\`e}re, Baptiste and Goyal, Naman and Hambro, Eric and Azhar, Faisal and others},
  journal={arXiv preprint arXiv:2302.13971},
  year={2023}
}
@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}
@inproceedings{Zhang2015CharacterlevelCN,
  title={Character-level Convolutional Networks for Text Classification},
  author={Xiang Zhang and Junbo Jake Zhao and Yann LeCun},
  booktitle={NIPS},
  year={2015}
}
@inproceedings{li2023learning,
  title={Learning compact features via in-training representation alignment},
  author={Li, Xin and Li, Xiangrui and Pan, Deng and Qiang, Yao and Zhu, Dongxiao},
  booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
  volume={37},
  number={7},
  pages={8675--8683},
  year={2023}
}
@inproceedings{socher2013recursive,
  title={Recursive deep models for semantic compositionality over a sentiment treebank},
  author={Socher, Richard and Perelygin, Alex and Wu, Jean and Chuang, Jason and Manning, Christopher D and Ng, Andrew Y and Potts, Christopher},
  booktitle={Proceedings of the 2013 conference on empirical methods in natural language processing},
  pages={1631--1642},
  year={2013}
}
@inproceedings{qiang2020toward,
  title={Toward tag-free aspect based sentiment analysis: A multiple attention network approach},
  author={Qiang, Yao and Li, Xin and Zhu, Dongxiao},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2020},
  organization={IEEE}
}
@inproceedings{qiang2022tiny,
  title={Tiny rnn model with certified robustness for text classification},
  author={Qiang, Yao and Kumar, Supriya Tumkur Suresh and Brocanelli, Marco and Zhu, Dongxiao},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)},
  pages={1--8},
  year={2022},
  organization={IEEE}
}
@article{wang2023large,
  title={Are Large Language Models Really Robust to Word-Level Perturbations?},
  author={Wang, Haoyu and Ma, Guozheng and Yu, Cong and Gui, Ning and Zhang, Linrui and Huang, Zhiqi and Ma, Suwei and Chang, Yongzhe and Zhang, Sen and Shen, Li and others},
  journal={arXiv preprint arXiv:2309.11166},
  year={2023}
}
@inproceedings{li2021improving,
  title={Improving adversarial robustness via probabilistically compact loss with logit constraints},
  author={Li, Xin and Li, Xiangrui and Pan, Deng and Zhu, Dongxiao},
  booktitle={Proceedings of the AAAI conference on artificial intelligence},
  volume={35},
  number={10},
  pages={8482--8490},
  year={2021}
}
@article{chiang2023vicuna,
  title={Vicuna: An open-source chatbot impressing gpt-4 with 90\%* chatgpt quality},
  author={Chiang, Wei-Lin and Li, Zhuohan and Lin, Zi and Sheng, Ying and Wu, Zhanghao and Zhang, Hao and Zheng, Lianmin and Zhuang, Siyuan and Zhuang, Yonghao and Gonzalez, Joseph E and others},
  journal={See https://vicuna. lmsys. org (accessed 14 April 2023)},
  volume={2},
  number={3},
  pages={6},
  year={2023}
}
@article{alon2023detecting,
  title={Detecting language model attacks with perplexity},
  author={Alon, Gabriel and Kamfonas, Michael},
  journal={arXiv preprint arXiv:2308.14132},
  year={2023}
}
@article{jain2023baseline,
  title={Baseline defenses for adversarial attacks against aligned language models},
  author={Jain, Neel and Schwarzschild, Avi and Wen, Yuxin and Somepalli, Gowthami and Kirchenbauer, John and Chiang, Ping-yeh and Goldblum, Micah and Saha, Aniruddha and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2309.00614},
  year={2023}
}
@article{achiam2023gpt,
  title={Gpt-4 technical report},
  author={Achiam, Josh and Adler, Steven and Agarwal, Sandhini and Ahmad, Lama and Akkaya, Ilge and Aleman, Florencia Leoni and Almeida, Diogo and Altenschmidt, Janko and Altman, Sam and Anadkat, Shyamal and others},
  journal={arXiv preprint arXiv:2303.08774},
  year={2023}
}
@article{qiang2024prompt,
  title={Prompt perturbation consistency learning for robust language models},
  author={Qiang, Yao and Nandi, Subhrangshu and Mehrabi, Ninareh and Steeg, Greg Ver and Kumar, Anoop and Rumshisky, Anna and Galstyan, Aram},
  journal={arXiv preprint arXiv:2402.15833},
  year={2024}
}
@inproceedings{studnia2023evaluating,
  title={Evaluating Adversarial Defense in the Era of Large Language Models},
  author={Studnia, Joachim and Zuo, Simiao and Liu, Xiaodong and Lou, Qiang and Jiao, Jian and Charles, Denis},
  booktitle={R0-FoMo: Robustness of Few-shot and Zero-shot Learning in Large Foundation Models},
  year={2023}
}
@article{yuan2024rigorllm,
  title={RigorLLM: Resilient Guardrails for Large Language Models against Undesired Content},
  author={Yuan, Zhuowen and Xiong, Zidi and Zeng, Yi and Yu, Ning and Jia, Ruoxi and Song, Dawn and Li, Bo},
  journal={arXiv preprint arXiv:2403.13031},
  year={2024}
}
@article{formento2024semrode,
  title={SemRoDe: Macro Adversarial Training to Learn Representations That are Robust to Word-Level Attacks},
  author={Formento, Brian and Feng, Wenjie and Foo, Chuan Sheng and Tuan, Luu Anh and Ng, See-Kiong},
  journal={arXiv preprint arXiv:2403.18423},
  year={2024}
}
@article{mo2023trustworthy,
  title={How trustworthy are open-source llms? an assessment under malicious demonstrations shows their vulnerabilities},
  author={Mo, Lingbo and Wang, Boshi and Chen, Muhao and Sun, Huan},
  journal={arXiv preprint arXiv:2311.09447},
  year={2023}
}
@article{pezeshkpour2023large,
  title={Large language models sensitivity to the order of options in multiple-choice questions},
  author={Pezeshkpour, Pouya and Hruschka, Estevam},
  journal={arXiv preprint arXiv:2308.11483},
  year={2023}
}
@article{shayegani2023survey,
  title={Survey of vulnerabilities in large language models revealed by adversarial attacks},
  author={Shayegani, Erfan and Mamun, Md Abdullah Al and Fu, Yu and Zaree, Pedram and Dong, Yue and Abu-Ghazaleh, Nael},
  journal={arXiv preprint arXiv:2310.10844},
  year={2023}
}
@article{xu2024llm,
  title={LLM Jailbreak Attack versus Defense Techniques--A Comprehensive Study},
  author={Xu, Zihao and Liu, Yi and Deng, Gelei and Li, Yuekang and Picek, Stjepan},
  journal={arXiv preprint arXiv:2402.13457},
  year={2024}
}
@article{jeong2023hijacking,
  title={Hijacking Context in Large Multi-modal Models},
  author={Jeong, Joonhyun},
  journal={arXiv preprint arXiv:2312.07553},
  year={2023}
}
@article{qiang2024learning,
  title={Learning to Poison Large Language Models During Instruction Tuning},
  author={Qiang, Yao and Zhou, Xiangyu and Zade, Saleh Zare and Roshani, Mohammad Amin and Zytko, Douglas and Zhu, Dongxiao},
  journal={arXiv preprint arXiv:2402.13459},
  year={2024}
}
@article{zhao2024universal,
  title={Universal Vulnerabilities in Large Language Models: In-context Learning Backdoor Attacks},
  author={Zhao, Shuai and Jia, Meihuizi and Tuan, Luu Anh and Wen, Jinming},
  journal={arXiv preprint arXiv:2401.05949},
  year={2024}
}
@article{guo2024cold,
  title={Cold-attack: Jailbreaking llms with stealthiness and controllability},
  author={Guo, Xingang and Yu, Fangxu and Zhang, Huan and Qin, Lianhui and Hu, Bin},
  journal={arXiv preprint arXiv:2402.08679},
  year={2024}
}
@article{mehrotra2023tree,
  title={Tree of attacks: Jailbreaking black-box llms automatically},
  author={Mehrotra, Anay and Zampetakis, Manolis and Kassianik, Paul and Nelson, Blaine and Anderson, Hyrum and Singer, Yaron and Karbasi, Amin},
  journal={arXiv preprint arXiv:2312.02119},
  year={2023}
}
@inproceedings{qiang2022counterfactual,
  title={Counterfactual interpolation augmentation (CIA): A unified approach to enhance fairness and explainability of DNN},
  author={Qiang, Yao and Li, Chengyin and Brocanelli, Marco and Zhu, Dongxiao},
  booktitle={Proceedings of the Thirty-First International Joint Conference on Artificial Intelligence, IJCAI},
  pages={732--739},
  year={2022}
}
@article{qiang2022attcat,
  title={Attcat: Explaining transformers via attentive class activation tokens},
  author={Qiang, Yao and Pan, Deng and Li, Chengyin and Li, Xin and Jang, Rhongho and Zhu, Dongxiao},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={5052--5064},
  year={2022}
}
@article{qiang2023interpretability,
  title={Interpretability-Aware Vision Transformer},
  author={Qiang, Yao and Li, Chengyin and Khanduri, Prashant and Zhu, Dongxiao},
  journal={arXiv preprint arXiv:2309.08035},
  year={2023}
}
@article{wei2023larger,
  title={Larger language models do in-context learning differently},
  author={Wei, Jerry and Wei, Jason and Tay, Yi and Tran, Dustin and Webson, Albert and Lu, Yifeng and Chen, Xinyun and Liu, Hanxiao and Huang, Da and Zhou, Denny and others},
  journal={arXiv preprint arXiv:2303.03846},
  year={2023}
}
@article{wang2024mitigating,
  title={Mitigating Fine-tuning Jailbreak Attack with Backdoor Enhanced Alignment},
  author={Wang, Jiongxiao and Li, Jiazhao and Li, Yiquan and Qi, Xiangyu and Chen, Muhao and Hu, Junjie and Li, Yixuan and Li, Bo and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2402.14968},
  year={2024}
}
@article{xu2023instructions,
  title={Instructions as backdoors: Backdoor vulnerabilities of instruction tuning for large language models},
  author={Xu, Jiashu and Ma, Mingyu Derek and Wang, Fei and Xiao, Chaowei and Chen, Muhao},
  journal={arXiv preprint arXiv:2305.14710},
  year={2023}
}
@article{liu2023shortcuts,
  title={From shortcuts to triggers: Backdoor defense with denoised poe},
  author={Liu, Qin and Wang, Fei and Xiao, Chaowei and Chen, Muhao},
  journal={arXiv preprint arXiv:2305.14910},
  year={2023}
}
@article{wen2024hard,
  title={Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery},
  author={Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}
@inproceedings{kossen2023context,
  title={In-context learning learns label relationships but is not conventional learning},
  author={Kossen, Jannik and Gal, Yarin and Rainforth, Tom},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}
@article{li2023defending,
  title={Defending against insertion-based textual backdoor attacks via attribution},
  author={Li, Jiazhao and Wu, Zhuofeng and Ping, Wei and Xiao, Chaowei and Vydiswaran, VG},
  journal={arXiv preprint arXiv:2305.02394},
  year={2023}
}
@article{wu2024new,
  title={A New Era in LLM Security: Exploring Security Concerns in Real-World LLM-based Systems},
  author={Wu, Fangzhou and Zhang, Ning and Jha, Somesh and McDaniel, Patrick and Xiao, Chaowei},
  journal={arXiv preprint arXiv:2402.18649},
  year={2024}
}
@InProceedings{Pang+Lee:05a,
  author =       {Bo Pang and Lillian Lee},
  title =        {Seeing stars: Exploiting class relationships for sentiment
                  categorization with respect to rating scales},
  booktitle =    {Proceedings of the ACL},
  year =         2005
}
@article{yu2024don,
  title={Don't Listen To Me: Understanding and Exploring Jailbreak Prompts of Large Language Models},
  author={Yu, Zhiyuan and Liu, Xiaogeng and Liang, Shunning and Cameron, Zach and Xiao, Chaowei and Zhang, Ning},
  journal={arXiv preprint arXiv:2403.17336},
  year={2024}
}
@article{zhu2023autodan,
  title={AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models},
  author={Zhu, Sicheng and Zhang, Ruiyi and An, Bang and Wu, Gang and Barrow, Joe and Wang, Zichao and Huang, Furong and Nenkova, Ani and Sun, Tong},
  journal={arXiv preprint arXiv:2310.15140},
  year={2023}
}
@article{tang2023large,
  title={Large Language Models Can be Lazy Learners: Analyze Shortcuts in In-Context Learning},
  author={Tang, Ruixiang and Kong, Dehan and Huang, Longtao and Xue, Hui},
  journal={arXiv preprint arXiv:2305.17256},
  year={2023}
}
@article{ebrahimi2017hotflip,
  title={Hotflip: White-box adversarial examples for text classification},
  author={Ebrahimi, Javid and Rao, Anyi and Lowd, Daniel and Dou, Dejing},
  journal={arXiv preprint arXiv:1712.06751},
  year={2017}
}
@inproceedings{maus2023black,
  title={Black box adversarial prompting for foundation models},
  author={Maus, Natalie and Chao, Patrick and Wong, Eric and Gardner, Jacob R},
  booktitle={The Second Workshop on New Frontiers in Adversarial Machine Learning},
  year={2023}
}
@article{morris2020textattack,
  title={Textattack: A framework for adversarial attacks, data augmentation, and adversarial training in nlp},
  author={Morris, John X and Lifland, Eli and Yoo, Jin Yong and Grigsby, Jake and Jin, Di and Qi, Yanjun},
  journal={arXiv preprint arXiv:2005.05909},
  year={2020}
}
@inproceedings{zhao2021calibrate,
  title={Calibrate before use: Improving few-shot performance of language models},
  author={Zhao, Zihao and Wallace, Eric and Feng, Shi and Klein, Dan and Singh, Sameer},
  booktitle={International Conference on Machine Learning},
  pages={12697--12706},
  year={2021},
  organization={PMLR}
}
@article{shin2020autoprompt,
  title={Autoprompt: Eliciting knowledge from language models with automatically generated prompts},
  author={Shin, Taylor and Razeghi, Yasaman and Logan IV, Robert L and Wallace, Eric and Singh, Sameer},
  journal={arXiv preprint arXiv:2010.15980},
  year={2020}
}
@article{kim2022self,
  title={Self-generated in-context learning: Leveraging auto-regressive language models as a demonstration generator},
  author={Kim, Hyuhng Joon and Cho, Hyunsoo and Kim, Junyeob and Kim, Taeuk and Yoo, Kang Min and Lee, Sang-goo},
  journal={arXiv preprint arXiv:2206.08082},
  year={2022}
}
@article{zou2023universal,
  title={Universal and transferable adversarial attacks on aligned language models},
  author={Zou, Andy and Wang, Zifan and Kolter, J Zico and Fredrikson, Matt},
  journal={arXiv preprint arXiv:2307.15043},
  year={2023}
}
@article{chen2022relation,
  title={On the relation between sensitivity and accuracy in in-context learning},
  author={Chen, Yanda and Zhao, Chen and Yu, Zhou and McKeown, Kathleen and He, He},
  journal={arXiv preprint arXiv:2209.07661},
  year={2022}
}
@article{dong2022survey,
  title={A survey for in-context learning},
  author={Dong, Qingxiu and Li, Lei and Dai, Damai and Zheng, Ce and Wu, Zhiyong and Chang, Baobao and Sun, Xu and Xu, Jingjing and Sui, Zhifang},
  journal={arXiv preprint arXiv:2301.00234},
  year={2022}
}
@article{shen2023anything,
  title={" Do Anything Now": Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models},
  author={Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Shen, Yun and Zhang, Yang},
  journal={arXiv preprint arXiv:2308.03825},
  year={2023}
}
@article{wei2022emergent,
  title={Emergent abilities of large language models},
  author={Wei, Jason and Tay, Yi and Bommasani, Rishi and Raffel, Colin and Zoph, Barret and Borgeaud, Sebastian and Yogatama, Dani and Bosma, Maarten and Zhou, Denny and Metzler, Donald and others},
  journal={arXiv preprint arXiv:2206.07682},
  year={2022}
}
@article{li2020bert,
  title={Bert-attack: Adversarial attack against bert using bert},
  author={Li, Linyang and Ma, Ruotian and Guo, Qipeng and Xue, Xiangyang and Qiu, Xipeng},
  journal={arXiv preprint arXiv:2004.09984},
  year={2020}
}
@article{schaeffer2023emergent,
  title={Are emergent abilities of Large Language Models a mirage?},
  author={Schaeffer, Rylan and Miranda, Brando and Koyejo, Sanmi},
  journal={arXiv preprint arXiv:2304.15004},
  year={2023}
}
@article{wen2023hard,
  title={Hard prompts made easy: Gradient-based discrete optimization for prompt tuning and discovery},
  author={Wen, Yuxin and Jain, Neel and Kirchenbauer, John and Goldblum, Micah and Geiping, Jonas and Goldstein, Tom},
  journal={arXiv preprint arXiv:2302.03668},
  year={2023}
}
@article{ganguli2022red,
  title={Red teaming language models to reduce harms: Methods, scaling behaviors, and lessons learned},
  author={Ganguli, Deep and Lovitt, Liane and Kernion, Jackson and Askell, Amanda and Bai, Yuntao and Kadavath, Saurav and Mann, Ben and Perez, Ethan and Schiefer, Nicholas and Ndousse, Kamal and others},
  journal={arXiv preprint arXiv:2209.07858},
  year={2022}
}
@article{li2023multi,
  title={Multi-step jailbreaking privacy attacks on chatgpt},
  author={Li, Haoran and Guo, Dadi and Fan, Wei and Xu, Mingshi and Song, Yangqiu},
  journal={arXiv preprint arXiv:2304.05197},
  year={2023}
}
@article{casper2023explore,
  title={Explore, Establish, Exploit: Red Teaming Language Models from Scratch},
  author={Casper, Stephen and Lin, Jason and Kwon, Joe and Culp, Gatlen and Hadfield-Menell, Dylan},
  journal={arXiv preprint arXiv:2306.09442},
  year={2023}
}
@article{kang2023exploiting,
  title={Exploiting programmatic behavior of llms: Dual-use through standard security attacks},
  author={Kang, Daniel and Li, Xuechen and Stoica, Ion and Guestrin, Carlos and Zaharia, Matei and Hashimoto, Tatsunori},
  journal={arXiv preprint arXiv:2302.05733},
  year={2023}
}
@article{lu2021fantastically,
  title={Fantastically ordered prompts and where to find them: Overcoming few-shot prompt order sensitivity},
  author={Lu, Yao and Bartolo, Max and Moore, Alastair and Riedel, Sebastian and Stenetorp, Pontus},
  journal={arXiv preprint arXiv:2104.08786},
  year={2021}
}
@article{perez2022ignore,
  title={Ignore previous prompt: Attack techniques for language models},
  author={Perez, F{\'a}bio and Ribeiro, Ian},
  journal={arXiv preprint arXiv:2211.09527},
  year={2022}
}
@article{min2022rethinking,
  title={Rethinking the role of demonstrations: What makes in-context learning work?},
  author={Min, Sewon and Lyu, Xinxi and Holtzman, Ari and Artetxe, Mikel and Lewis, Mike and Hajishirzi, Hannaneh and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:2202.12837},
  year={2022}
}
@article{carlini2023aligned,
  title={Are aligned neural networks adversarially aligned?},
  author={Carlini, Nicholas and Nasr, Milad and Choquette-Choo, Christopher A and Jagielski, Matthew and Gao, Irena and Awadalla, Anas and Koh, Pang Wei and Ippolito, Daphne and Lee, Katherine and Tramer, Florian and others},
  journal={arXiv preprint arXiv:2306.15447},
  year={2023}
}
@inproceedings{zhuang2023pilot,
  title={A pilot study of query-free adversarial attack against stable diffusion},
  author={Zhuang, Haomin and Zhang, Yihua and Liu, Sijia},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2384--2391},
  year={2023}
}
@article{li2018textbugger,
  title={Textbugger: Generating adversarial text against real-world applications},
  author={Li, Jinfeng and Ji, Shouling and Du, Tianyu and Li, Bo and Wang, Ting},
  journal={arXiv preprint arXiv:1812.05271},
  year={2018}
}
@article{liu2021makes,
  title={What Makes Good In-Context Examples for GPT-$3 $?},
  author={Liu, Jiachang and Shen, Dinghan and Zhang, Yizhe and Dolan, Bill and Carin, Lawrence and Chen, Weizhu},
  journal={arXiv preprint arXiv:2101.06804},
  year={2021}
}
@article{wu2022self,
  title={Self-adaptive in-context learning},
  author={Wu, Zhiyong and Wang, Yaoxiang and Ye, Jiacheng and Kong, Lingpeng},
  journal={arXiv preprint arXiv:2212.10375},
  year={2022}
}
@article{shen2023chatgpt,
  title={In chatgpt we trust? measuring and characterizing the reliability of chatgpt},
  author={Shen, Xinyue and Chen, Zeyuan and Backes, Michael and Zhang, Yang},
  journal={arXiv preprint arXiv:2304.08979},
  year={2023}
}
@article{wang2023robustness,
  title={On the robustness of chatgpt: An adversarial and out-of-distribution perspective},
  author={Wang, Jindong and Hu, Xixu and Hou, Wenxin and Chen, Hao and Zheng, Runkai and Wang, Yidong and Yang, Linyi and Huang, Haojun and Ye, Wei and Geng, Xiubo and others},
  journal={arXiv preprint arXiv:2302.12095},
  year={2023}
}
@article{zhu2023promptbench,
  title={PromptBench: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts},
  author={Zhu, Kaijie and Wang, Jindong and Zhou, Jiaheng and Wang, Zichen and Chen, Hao and Wang, Yidong and Yang, Linyi and Ye, Wei and Gong, Neil Zhenqiang and Zhang, Yue and others},
  journal={arXiv preprint arXiv:2306.04528},
  year={2023}
}
@article{devlin2018bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  journal={arXiv preprint arXiv:1810.04805},
  year={2018}
}
@article{lewis2019bart,
  title={Bart: Denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension},
  author={Lewis, Mike and Liu, Yinhan and Goyal, Naman and Ghazvininejad, Marjan and Mohamed, Abdelrahman and Levy, Omer and Stoyanov, Ves and Zettlemoyer, Luke},
  journal={arXiv preprint arXiv:1910.13461},
  year={2019}
}
@article{rubin2021learning,
  title={Learning to retrieve prompts for in-context learning},
  author={Rubin, Ohad and Herzig, Jonathan and Berant, Jonathan},
  journal={arXiv preprint arXiv:2112.08633},
  year={2021}
}
@article{xie2021explanation,
  title={An explanation of in-context learning as implicit bayesian inference},
  author={Xie, Sang Michael and Raghunathan, Aditi and Liang, Percy and Ma, Tengyu},
  journal={arXiv preprint arXiv:2111.02080},
  year={2021}
}
@article{razeghi2022impact,
  title={Impact of pretraining term frequencies on few-shot reasoning},
  author={Razeghi, Yasaman and Logan IV, Robert L and Gardner, Matt and Singh, Sameer},
  journal={arXiv preprint arXiv:2202.07206},
  year={2022}
}