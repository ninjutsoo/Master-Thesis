\contentsline {table}{\numberline {1}{\ignorespaces Statistics of the training queries used in Algorithm \ref {alg} and test queries for the three datasets. }}{16}{table.caption.6}%
\contentsline {table}{\numberline {2}{\ignorespaces The performance on sentiment analysis task with and without attacks on ICL. The row identified as `Clean' in gray color represents the accuracy with clean in-context demos. Other rows illustrate the accuracies with adversarial in-context demos. The details of the baselines in green color are present in Section \ref {text: baseline}. Specifically, we employ TextAttack (TA) \cite {morris2020textattack} following the attack in \cite {wang2023adversarial} as the most closely related baseline for our attack (GGI). The accuracies of positive (\textcolor {red}{P}) and negative (\textcolor {blue}{N}) sentiments are reported separately to highlight the effectiveness of our hijacking attack. }}{21}{table.caption.8}%
\contentsline {table}{\numberline {3}{\ignorespaces The performance of AG's News topic generation task with and without attacks on ICL. The clean and attack accuracies are reported separately for the four topics. These results highlight the effectiveness of our hijacking attacks to induce LLMs to generate the target token, i.e., ``tech'', regardless of the query content. }}{22}{table.caption.9}%
\contentsline {table}{\numberline {4}{\ignorespaces ASR among different datasets, models, and attack methods. Best scores are in bold.}}{22}{table.caption.10}%
\contentsline {table}{\numberline {5}{\ignorespaces The performance of the defenses using ASRs across various LLMs and datasets. Adv denotes our hijacking attack using the adversarial demos. Adv+Clean represents the proposed defense method, leveraging extra clean demos with adversarial demos. The numbers within the parenthesis indicate the reduction in the ASRs after defense. }}{23}{table.caption.11}%
